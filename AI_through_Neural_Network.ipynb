{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_neural_network:\n",
    "    \n",
    "    def __init__(self, hidden_layer_plan):\n",
    "        \n",
    "        '''\n",
    "        Initialization function.\n",
    "        \n",
    "        input: \n",
    "        layer_plan : data_type = list\n",
    "        \n",
    "        List cointaing the number of neurons in every layers for the neural network. The first and last elements of\n",
    "        layer_plan corresponds to number of input features and the output value. \n",
    "        The rest of the elements between them corresponds to the neurons in hidden layers.\n",
    "        More the Hidden Layers implies deeper the network!\n",
    "        '''\n",
    "        \n",
    "        #dataset\n",
    "        self.dataset = None\n",
    "        \n",
    "        #input and output data\n",
    "        self.input_data = None\n",
    "        self.output_data = None\n",
    "        self.predicted_output =None\n",
    "        \n",
    "        #train and test data\n",
    "        self.training_data = None\n",
    "        self.testing_data = None\n",
    "        \n",
    "        #layer details\n",
    "        self.hidden_layer_plan = hidden_layer_plan\n",
    "        self.layer_dimensions = None\n",
    "        self.num_of_layers = None\n",
    "        \n",
    "        #Batching\n",
    "        self.mini_batches = []\n",
    "        \n",
    "        #Forward Activation\n",
    "        self.activations, self.Z = [], []\n",
    "        \n",
    "        #Backward Activation\n",
    "        self.dActivations = []\n",
    "        \n",
    "        #Error_method and loss\n",
    "        self.error_method = None\n",
    "        self.loss = None\n",
    "        self.cost = []\n",
    "        self.cost_value = None\n",
    "        \n",
    "        #Network parameters\n",
    "        self.network_parameters, self.gradient_network_parameters = {}, {}\n",
    "        self.steep_parameters, self.adam_parameters = {}, {}\n",
    "        #optimizer\n",
    "        self.optimizer = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        ''' Representative function to welcome the user for collaborating with the new AI trainer'''\n",
    "        return 'Hello there!! I am your new AI trainer......!'\n",
    "    \n",
    "    \n",
    "    def load_dataset(self, file):\n",
    "        ''' \n",
    "        To load dataset \n",
    "        \n",
    "        input:\n",
    "        file : data_type: string\n",
    "        File name consisting the inputs and outputs. The last column in the file is the output.\n",
    "        '''\n",
    "        self.dataset = np.loadtxt(file)\n",
    "        self.input_data = self.dataset[:,:-1]\n",
    "        self.output_data = self.dataset[:,-1]\n",
    "        \n",
    "        #Normalization\n",
    "        #max_inputs = np.amax(self.input_data, axis=0)\n",
    "        #self.input_data = np.divide(self.input_data, max_inputs)\n",
    "        \n",
    "        #max_outputs = np.amax(self.output_data, axis=0)\n",
    "        #self.output_data = np.divide(self.output_data, max_outputs)\n",
    "        \n",
    "        #Layer planning\n",
    "        self.layer_dimensions = [self.input_data.shape[1]]+self.hidden_layer_plan+[1] #1 corresponds to columns in O/P\n",
    "        self.num_of_layers = len(self.layer_dimensions)\n",
    "        \n",
    "    def test_train_split(self, split = 0.7):\n",
    "        '''\n",
    "        This function is utilized to segragate the complete data into training and testing data.\n",
    "        '''\n",
    "        \n",
    "        n_total = int(self.dataset.shape[0])\n",
    "        n_train = int(split*n_total)\n",
    "        \n",
    "        mask = np.zeros((n_total), dtype=bool)\n",
    "        mask[:n_train] = True\n",
    "        \n",
    "        np.random.shuffle(mask)\n",
    "        \n",
    "        X_train = self.input_data[mask]\n",
    "        Y_train = self.output_data[mask]\n",
    "        \n",
    "        X_test = self.input_data[~mask]\n",
    "        Y_test = self.output_data[~mask]\n",
    "        \n",
    "        self.training_data = (X_train.transpose(), Y_train)\n",
    "        self.testing_data = (X_test.transpose(), Y_test)\n",
    "    \n",
    "    def network_parameters_initialization(self):\n",
    "        np.random.seed(1)\n",
    "        for i in range(1,self.num_of_layers):\n",
    "            self.network_parameters['Weights'+str(i)] = np.random.randn(self.layer_dimensions[i], \n",
    "                                                                         self.layer_dimensions[i-1])\n",
    "            self.network_parameters['bias'+str(i)] = np.random.randn(self.layer_dimensions[i],1)\n",
    "            \n",
    "            assert(self.network_parameters['Weights'+str(i)].shape == (self.layer_dimensions[i], \n",
    "                                                                         self.layer_dimensions[i-1]))\n",
    "            assert(self.network_parameters['bias'+str(i)].shape == (self.layer_dimensions[i],1))\n",
    "            \n",
    "            self.gradient_network_parameters['dWeights'+str(i)] = np.zeros_like(self.network_parameters['Weights'+str(i)]) #np.zeros((self.layer_dimensions[i], self.layer_dimensions[i-1]))\n",
    "                                                                         #\n",
    "            self.gradient_network_parameters['dbias'+str(i)] = np.zeros_like(self.network_parameters['bias'+str(i)])#np.zeros((self.layer_dimensions[i],1))\n",
    "            \n",
    "            self.steep_parameters['dWeights'+str(i)] = np.zeros_like(self.network_parameters['Weights'+str(i)])\n",
    "            \n",
    "            self.steep_parameters['dbias'+str(i)] = np.zeros_like(self.network_parameters['bias'+str(i)])\n",
    "            \n",
    "            self.adam_parameters['dWeights'+str(i)] = np.zeros_like(self.network_parameters['Weights'+str(i)])\n",
    "            \n",
    "            self.adam_parameters['dbias'+str(i)] = np.zeros_like(self.network_parameters['bias'+str(i)])\n",
    "     \n",
    "    def batching(self, batching = False, batch_size = None):\n",
    "        '''\n",
    "        The NN_gradient_descent function helps to build and get the deep network working. \n",
    "        \n",
    "        inputs:\n",
    "        learning_rate : floating number\n",
    "        This is an hyper parameter which is used in gradient descent\n",
    "        '''\n",
    "        num_examples = self.training_data[0].shape[1]\n",
    "              \n",
    "        \n",
    "        if batching:\n",
    "            \n",
    "            training_input = self.training_data[0]\n",
    "            training_output = self.training_data[1]\n",
    "            \n",
    "            #mini_batches = []\n",
    "            \n",
    "            number_of_batches = int(num_examples/batch_size)\n",
    "            \n",
    "            for j in range(0,number_of_batches):\n",
    "                mini_train_input = training_input[:,(j*batch_size):((j+1)*batch_size)]\n",
    "                mini_train_output = training_output[:,(j*batch_size):((j+1)*batch_size)]\n",
    "                self.mini_batches.append((mini_train_input,mini_train_output))\n",
    "                \n",
    "            if num_examples % batch_size != 0:\n",
    "                mini_train_input = training_input[:,(number_of_batches*batch_size):]\n",
    "                mini_train_output = training_output[:,(number_of_batches*batch_size):]\n",
    "                self.mini_batches.append((mini_train_input,mini_train_output))\n",
    "        else:\n",
    "            \n",
    "            self.mini_batches = [self.training_data]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def sigmoid(self,Z):\n",
    "        return 1./(1+np.exp(-Z))\n",
    "\n",
    "    def sigmoid_derivative(self,Z):\n",
    "        return self.sigmoid(Z)*(1-self.sigmoid(Z))\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        self.activations = [X]\n",
    "        for l in range(self.num_of_layers-1):\n",
    "\n",
    "            Z = np.dot(self.network_parameters['Weights'+str(l+1)], self.activations[l])+self.network_parameters['bias'+str(l+1)]\n",
    "\n",
    "            activated_Z = self.sigmoid(Z)\n",
    "\n",
    "            self.Z.append(Z)\n",
    "            self.activations.append(activated_Z)\n",
    "\n",
    "    def cost_function(self, error_method = 'MSE',test = False):\n",
    "        self.error_method = error_method\n",
    "        if test:\n",
    "            y_o = self.testing_data[1]\n",
    "        else:\n",
    "            y_o = self.training_data[1]\n",
    "        if error_method == 'MSE':\n",
    "            cost = 0.5*np.mean(np.square(self.activations[-1] - y_o))\n",
    "            self.cost_value = np.squeeze(cost)\n",
    "        \n",
    "\n",
    "    def cost_function_derivative(self, test=False):\n",
    "        if test:\n",
    "            y_o = self.testing_data[1]\n",
    "        else:\n",
    "            y_o = self.training_data[1]\n",
    "            \n",
    "        if self.error_method == 'MSE':\n",
    "            delC_delA = self.activations[-1] - y_o\n",
    "\n",
    "        self.loss = delC_delA\n",
    "\n",
    "    def back_propagation(self,X,Y):\n",
    "        \n",
    "        delC_delA = self.loss\n",
    "\n",
    "        #For Last Layer\n",
    "\n",
    "        #delC _delZ = delC_delA * delA_delZ\n",
    "        delC_delZ = delC_delA*self.sigmoid_derivative(self.Z[-1])\n",
    "        #delC_delB =  delC_delA * delA_delZ * delZ_delB\n",
    "        delC_delB = np.mean(delC_delZ, axis=1)\n",
    "        #delC_delW =  delC_delA * delA_delZ * delZ_delW\n",
    "        delC_delW = np.dot(delC_delZ,self.activations[-2].transpose())\n",
    "\n",
    "        self.gradient_network_parameters['dWeights'+str(self.num_of_layers-1)] = delC_delW\n",
    "        assert ( self.gradient_network_parameters['dWeights'+str(self.num_of_layers-1)].shape == self.network_parameters['Weights'+str(self.num_of_layers-1)].shape)\n",
    "        self.gradient_network_parameters['dbias'+str(self.num_of_layers-1)] = delC_delB.reshape(self.network_parameters['bias'+str(self.num_of_layers-1)].shape)\n",
    "        #assert ( self.gradient_network_parameters['dbias'+str(self.num_of_layers-1)].shape == self.network_parameters['bias'+str(self.num_of_layers-1)].shape)\n",
    "\n",
    "        for i in reversed(range(2,self.num_of_layers)):\n",
    "            delC_delA = np.dot(self.network_parameters['Weights'+str(i)].transpose(),delC_delZ)\n",
    "            delC_delZ = delC_delA*self.sigmoid_derivative(self.Z[i-2])\n",
    "            delC_delB = np.mean(delC_delZ, axis=1)\n",
    "            delC_delW = (1.0/X.shape[1])*np.dot(delC_delZ,self.activations[i-2].transpose())\n",
    "\n",
    "            self.gradient_network_parameters['dWeights'+str(i-1)] = delC_delW\n",
    "            assert ( self.gradient_network_parameters['dWeights'+str(i-1)].shape == self.network_parameters['Weights'+str(i-1)].shape)\n",
    "            self.gradient_network_parameters['dbias'+str(i-1)] = delC_delB.reshape(self.network_parameters['bias'+str(i-1)].shape)\n",
    "            assert ( self.gradient_network_parameters['dbias'+str(i-1)].shape == self.network_parameters['bias'+str(i-1)].shape)\n",
    "\n",
    "    def update_parameters_GD(self,learning_rate):\n",
    "            ''' Implementation of gradient descent method '''\n",
    "            for p in range(1,self.num_of_layers):\n",
    "\n",
    "                self.network_parameters['Weights'+str(p)] -= learning_rate*self.gradient_network_parameters['dWeights'+str(p)]\n",
    "\n",
    "                self.network_parameters['bias'+str(p)] -= learning_rate*self.gradient_network_parameters['dbias'+str(p)]\n",
    "\n",
    "    \n",
    "    def update_parameters_steepestGD(self,learning_rate,beta1):\n",
    "        '''Implementation of Steepest Gradient descent Method'''\n",
    "        \n",
    "        for p in range(1,self.num_of_layers):\n",
    "            \n",
    "            self.steep_parameters['dWeights'+str(p)] = beta1*self.steep_parameters['dWeights'+str(p)] + (1-beta1)*self.gradient_network_parameters['dWeights'+str(p)]\n",
    "            self.steep_parameters['dbias'+str(p)] = beta1*self.steep_parameters['dbias'+str(p)] + (1-beta1)*self.gradient_network_parameters['dbias'+str(p)]\n",
    "            \n",
    "            self.network_parameters['Weights'+str(p)] -= learning_rate*self.steep_parameters['dWeights'+str(p)]\n",
    "            self.network_parameters['bias'+str(p)] -= learning_rate*self.steep_parameters['dbias'+str(p)] \n",
    "    \n",
    "    def NN_model(self, epochs, learning_rate, beta1 , batching=False, batch_size = None,  error_method = 'MSE', optimizer='GD'):\n",
    "        \n",
    "        ''' Deep neural network model'''\n",
    "        \n",
    "        self.network_parameters_initialization()\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        for iteration in range(epochs):\n",
    "            \n",
    "            #Batching\n",
    "            self.batching(batching=False, batch_size=None)\n",
    "            \n",
    "            #Traversing through Mini Batches:\n",
    "            for mini_batch in self.mini_batches:\n",
    "                \n",
    "                mini_batch_X, mini_batch_Y = mini_batch\n",
    "                \n",
    "                #Forward Prop\n",
    "                self.forward_propagation(mini_batch_X)\n",
    "                \n",
    "                #Loss calculation\n",
    "                self.cost_function(error_method)\n",
    "                self.cost_function_derivative()\n",
    "\n",
    "                if iteration%(epochs/10) == 0:\n",
    "                    self.cost.append(np.squeeze(np.mean(self.loss)))\n",
    "                    print('The cost after iteration: ', iteration, 'is :', np.squeeze(np.mean(self.loss)))\n",
    "                #Back Prop\n",
    "                self.back_propagation(mini_batch_X,mini_batch_Y)\n",
    "                \n",
    "                if self.optimizer == 'GD':\n",
    "                    #Updating parameters with Gradient Descent\n",
    "                    self.update_parameters_GD(learning_rate)\n",
    "                \n",
    "                elif self.optimizer == 'Steepest GD':\n",
    "                    #Updating parameters with Steepest Gradient\n",
    "                    self.update_parameters_steepestGD(learning_rate, beta1)\n",
    "                    \n",
    "                \n",
    "    \n",
    "                \n",
    "        #prediction\n",
    "        prediction_train = self.training_data[0]\n",
    "        self.forward_propagation(prediction_train)\n",
    "        \n",
    "        #Evaluation\n",
    "        self.evaluate()\n",
    "        \n",
    "        \n",
    "    def evaluate(self):\n",
    "        prediction_test = self.testing_data[0]\n",
    "        self.forward_propagation(prediction_test)\n",
    "        \n",
    "        self.cost_function(self.error_method, test=True)\n",
    "        print('The cost in Testing is: ', self.cost_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#import numpy as np\n",
    "data = np.loadtxt('log.txt')\n",
    "data1 = np.zeros((data.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after iteration:  0 is : 0.5149632041252459\n",
      "The cost after iteration:  25000 is : 0.029483554162489885\n",
      "The cost after iteration:  50000 is : 0.0471349697775356\n",
      "The cost after iteration:  75000 is : 0.04457245386526275\n",
      "The cost after iteration:  100000 is : 0.03197106766460593\n",
      "The cost after iteration:  125000 is : 0.0228735341959655\n",
      "The cost after iteration:  150000 is : 0.017512683062269583\n",
      "The cost after iteration:  175000 is : 0.014216151765771604\n",
      "The cost after iteration:  200000 is : 0.01203461979591025\n",
      "The cost after iteration:  225000 is : 0.01049588920513732\n",
      "The cost in Testing is:  0.001603937802057703\n"
     ]
    }
   ],
   "source": [
    "#def NN_model(self, epochs, learning_rate, beta1 , batching=False, batch_size = None,  error_method = 'MSE', optimizer='GD')\n",
    "hidden_layer_dims = [5,5]\n",
    "model = my_neural_network(hidden_layer_dims)\n",
    "file_name = 'XOR_data.txt'\n",
    "model.load_dataset(file_name)\n",
    "model.test_train_split()\n",
    "model.NN_model(250000, 0.0007,0.9, batching = True, batch_size= 64,optimizer = 'Steepest GD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(model.cost))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting testing output v/s predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(model.testing_data[1],np.round(model.activations[-1].reshape(model.testing_data[1].shape)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
